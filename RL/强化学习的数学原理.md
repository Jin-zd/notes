# 1 基本概念
状态、状态空间；动作、动作空间；
状态转移：当采取一个动作，智能体从一个状态转移到另一个状态。
策略：智能体在一个状态应该采取什么动作。

奖励：智能体采取动作后获得的一个实数值，正为鼓励，负为惩罚。
轨迹：一条轨迹是一个状态-动作-奖励链。

马尔科夫决策过程（MDP）：
状态空间：$S$
动作空间：$A(s),\; s \in S$
奖励：$R(s, a),\; s \in S,\; a \in A(s)$
状态转移概率：$p(s'\;| s,\; a),\; s \in S,\; a \in A(s)$
策略：$\pi (a\;|s),\; s \in S,\; a \in A(s)$
马尔可夫性质：未来状态的条件转移概率只依赖于当前的状态和动作，与过去的状态和动作是独立的。


# 2 贝尔曼公式
