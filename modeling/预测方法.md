## 灰色预测模型
### 1.GM(1, 1)预测模型
适用于具有较强指数规律的序列。
已知参考数列 $x^{(0)} = (\; x^{(0)}(1),\; x^{(0)}(1),\; ...,\; x^{(0)}(n)\; )$ ，
一次累加生成序列（1-AGO）为
$$
x^{(1)} = (\; x^{(1)}(1),\; x^{(1)}(1),\; ...,\; x^{(1)}(n)\; ),
$$
其中 $x^{(1)}(k) = \sum\limits_{i = 1}^kx^{(0)}(i),\; k = 1, 2, ..., n$ ，
$x^{(1)}$ 的均值生成数列为
$$
z^{(1)} = (\; z^{(1)}(1),\; z^{(1)}(1),\; ...,\; z^{(1)}(n)\; ),
$$
其中 $z^{(1)}(k) = 0.5x^{(1)}(k) + 0.5x^{(1)}(k - 1),\; k = 2, 3, ..., n$ ，
建立灰微分方程
$$
x^{(0)}(k) + az^{(1)}(k) = b,\quad k = 1, 2, ..., n,
$$
相应的白化微分方程为
$$
\frac{dx^{(1)}(t)}{dt} + ax^{(1)}(t) = b,
$$
记 
$$
u = [\; a,\; b\;]^T,\quad 
Y =[\; x^{(0)}(2),\; x^{(0)}(3),\; ...,\; x^{(0)}(n)\; ],\quad
B = 
\begin{bmatrix}
-z^{(1)}(2) & 1 \\
-z^{(1)}(3) & 1 \\
\vdots & \vdots \\
-z^{(1)}(n) & 1 
\end{bmatrix},
$$
由最小二乘法，得
$$
u = (B^TB)^{-1}B^TY,
$$
从而求解上述方程，得到
$$
\hat{x}^{(1)}(k + 1) = (x^{(0)}(1) - \cfrac{\hat{b}}{\hat{a}})e^{-\hat{a}k} + \cfrac{\hat{b}}{\hat{a}},\quad k = 0, 1, \cdots, n - 1, \cdots . 
$$
还原式为
$$
\hat{x}^{(0)}(k + 1) = \hat{x}^{(1)}(k + 1) - \hat{x}^{(1)}(k).
$$


在建立模型之前，需要对数据进行检验处理，
计算参考数列的级比
$$
\lambda(k) = \cfrac{x^{(0)}(k - 1)}{x^{(0)}(k)},\quad k = 1, 2, ..., n,
$$
若所有的 $\lambda(k)$ 都落在可容覆盖 $\Theta = (e^{-\frac{2}{n + 1}},\; e^{\frac{2}{n + 1}})$ 内，则序列 $x^{(0)}$ 可以作为 $GM(1,\; 1)$ 的数据进行预测，否则要对参考序列进行变换使其落入可容覆盖内；


预测数据之后，要对所得数据进行检验，
1）相对误差检验
$$
\delta(k) = \cfrac{|\; x^{(0)}(1) - \hat{x}^{(0)}(k)\; |}{x^{(0)}(k)},
$$
其中 $\hat{x}^{(0)}(1) = x^{(0)}(1)$ ，若 $\delta(k) < 0.2$ ，则可认为达到一般要求。
2）级比偏差值检验
$$
\rho(k) = |\; 1 - \cfrac{1 - 0.5\hat{a}}{1 + 0.5\hat{a}}\lambda(k) \; |,
$$
若 $\rho(k) < 0.2$ ，则可认为达到一般需求。



### 2.GM(2, 1)预测模型
已知参考数列 $x^{(0)} = (\; x^{(0)}(1),\; x^{(0)}(1),\; ...,\; x^{(0)}(n)\; )$ ，
一次累加生成序列（1-AGO）为
$$
x^{(1)} = (\; x^{(1)}(1),\; x^{(1)}(1),\; ...,\; x^{(1)}(n)\; ),
$$
其中 $x^{(1)}(k) = \sum\limits_{i = 1}^kx^{(0)}(i),\; k = 1, 2, ..., n$ ，
一次累减生成序列（1-IAGO）为
$$
\alpha^{(1)}x^{(0)} = (\; \alpha^{(1)}x^{(0)}(2),\; ...,\; \alpha^{(1)}x^{(0)}(n) \; ),
$$
其中 $\alpha^{(1)}x^{(0)}(k) = x^{(0)}(k) - x^{(0)}(k - 1),\; k = 2, 3, ..., n$ ，
$x^{(1)}$ 的均值生成数列为
$$
z^{(1)} = (\; z^{(1)}(1),\; z^{(1)}(1),\; ...,\; z^{(1)}(n)\; ),
$$
其中 $z^{(1)}(k) = 0.5x^{(1)}(k) + 0.5x^{(1)}(k - 1),\; k = 2, 3, ..., n$ ，
建立灰微分方程
$$
\alpha^{(1)}x^{(0)}(k) + a_1x^{0}(k) + a_2z^{(1)}(k) = b,\quad k = 1, 2, ..., n,
$$
相应的白化微分方程为
$$
\cfrac{d^2x^{(1)}(t)}{dt^2} + a_1\cfrac{dx^{(1)}(t)}{dt} + a_2x^{(1)}(t) = b,
$$
记
$$
\begin{array}
\left
u = [\; a_1,\; a_2,\; b\;]^T,\\ \\ 
Y =[\; \alpha^{(1)}x^{(0)}(2),\; \alpha^{(1)}x^{(0)}(3),\; ...,\; \alpha^{(1)}x^{(0)}(n)\; ]^T, \\ \\
B = 
\begin{bmatrix}
-x^{(0)}(2) & -z^{(1)}(2) & 1 \\
-x^{(0)}(3) & -z^{(1)}(3) & 1 \\
\vdots & \vdots & \vdots \\
-x^{(0)}(n) & -z^{(1)}(n) & 1 
\end{bmatrix},
\end{array}
$$
得到 $u$ 的最小二乘估计为
$$
\hat{u} = (B^TB)^{-1}B^TY. 
$$
还原式为
$$
\hat{x}^{(0)}(k + 1) = \hat{x}^{(1)}(k + 1) - \hat{x}^{(1)}(k).
$$



### 3.DGM(2, 1)预测模型
已知参考数列 $x^{(0)} = (\; x^{(0)}(1),\; x^{(0)}(1),\; ...,\; x^{(0)}(n)\; )$ ，
一次累加生成序列（1-AGO）为
$$
x^{(1)} = (\; x^{(1)}(1),\; x^{(1)}(1),\; ...,\; x^{(1)}(n)\; ),
$$
其中 $x^{(1)}(k) = \sum\limits_{i = 1}^kx^{(0)}(i),\; k = 1, 2, ..., n$ ，
一次累减生成序列（1-IAGO）为
$$
\alpha^{(1)}x^{(0)} = (\; \alpha^{(1)}x^{(0)}(2),\; ...,\; \alpha^{(1)}x^{(0)}(n) \; ),
$$
其中 $\alpha^{(1)}x^{(0)}(k) = x^{(0)}(k) - x^{(0)}(k - 1),\; k = 2, 3, ..., n$ ，
$x^{(1)}$ 的均值生成数列为
$$
z^{(1)} = (\; z^{(1)}(1),\; z^{(1)}(1),\; ...,\; z^{(1)}(n)\; ),
$$
其中 $z^{(1)}(k) = 0.5x^{(1)}(k) + 0.5x^{(1)}(k - 1),\; k = 2, 3, ..., n$ ，
建立灰微分方程
$$
\alpha^{(1)}x^{(0)}(k) + ax^{(0)}(k) = b,\quad k = 1, 2, ..., n,
$$
相应的白化微分方程为
$$
\cfrac{d^2x^{(1)}(t)}{dt} + a\cfrac{dx^{(1)}(t)}{dt} = b,
$$
记
$$
\begin{array}
\left
u = [\; a,\; b\;]^T,\\ \\ 
Y =[\; \alpha^{(1)}x^{(0)}(2),\; \alpha^{(1)}x^{(0)}(3),\; ...,\; \alpha^{(1)}x^{(0)}(n)\; ]^T, \\ \\
B = 
\begin{bmatrix}
-x^{(0)}(2) &  1 \\
-x^{(0)}(3) &  1 \\
\vdots & \vdots \\
-x^{(0)}(n) & 1 
\end{bmatrix},
\end{array}
$$
得到 $u$ 的最小二乘估计为
$$
\hat{u} = (B^TB)^{-1}B^TY. 
$$
取初值条件
$$
x^{(1)}(1) = x^{(0)}(1),\; \cfrac{dx^{(1)}(1)}{dt} = x^{(0)}(1),
$$
白化方程的时间响应序列为
$$
\hat{x}^{(1)}(t) = (\cfrac{\hat{b}}{\hat{a}^2} - \cfrac{x^{(0)}(1)}{\hat{a}})e^{-\hat{a}t} + \cfrac{\hat{b}}{\hat{a}}t + \cfrac{1 + \hat{a}}{\hat{a}}x^{(0)}(1) - \cfrac{\hat{b}}{\hat{a}^2},
$$
灰微分方程的时间响应序列为
$$
\hat{x}^{(1)}(k + 1) = (\cfrac{\hat{b}}{\hat{a}^2} - \cfrac{x^{(0)}(1)}{\hat{a}})e^{-\hat{a}k} + \cfrac{\hat{b}}{\hat{a}}k + \cfrac{1 + \hat{a}}{\hat{a}}x^{(0)}(1) - \cfrac{\hat{b}}{\hat{a}^2},
$$
还原式为
$$
\hat{x}^{(0)}(k + 1) = \hat{x}^{(1)}(k + 1) - \hat{x}^{(1)}(k).
$$

### 4.Verhulst预测模型
常用于 $S$ 型过程。
已知参考数列 $x^{(0)} = (\; x^{(0)}(1),\; x^{(0)}(1),\; ...,\; x^{(0)}(n)\; )$ ，
一次累加生成序列（1-AGO）为
$$
x^{(1)} = (\; x^{(1)}(1),\; x^{(1)}(1),\; ...,\; x^{(1)}(n)\; ),
$$
其中 $x^{(1)}(k) = \sum\limits_{i = 1}^kx^{(0)}(i),\; k = 1, 2, ..., n$ ，
$x^{(1)}$ 的均值生成数列为
$$
z^{(1)} = (\; z^{(1)}(1),\; z^{(1)}(1),\; ...,\; z^{(1)}(n)\; ),
$$
其中 $z^{(1)}(k) = 0.5x^{(1)}(k) + 0.5x^{(1)}(k - 1),\; k = 2, 3, ..., n$ ，
建立灰微分方程
$$
x^{(0)}(k) + az^{(1)}(k) = b[\; z^{(1)}(k)\;]^2,\quad k = 1, 2, ..., n,
$$
相应的白化微分方程为
$$
\cfrac{dx^{(1)}(t)}{dt} + ax^{(1)}t = b[\; x^{(1)}(t) \;]^2,
$$
记
$$
\begin{array}
\left
u = [\; a,\; b\;]^T,\\ \\
Y =[\; x^{(0)}(2),\; x^{(0)}(3),\; ...,\; x^{(0)}(n)\; ]^T, \\ \\ 
B = 
\begin{bmatrix}
-z^{(1)}(2) & (z^{(1)}(2))^2 &  1 \\
-z^{(1)}(3) & (z^{(1)}(3))^2 & 1 \\
\vdots & \vdots & \vdots\\
-z^{(1)}(n) & (z^{(1)}(n))^2 & 1 
\end{bmatrix},
\end{array}
$$
得到 $u$ 的最小二乘估计为
$$
\hat{u} = (B^TB)^{-1}B^TY. 
$$
白化方程的时间响应序列为
$$
x^{(1)}(t) = \cfrac{\hat{a}x^{(0)}(1)}{\hat{b}x^{(0)}(1) + (\hat{a} - \hat{b}x^{(0)}(1))e^{\hat{a}t}},
$$
灰微分方程的时间响应序列为
$$
x^{(1)}(k + 1) = \cfrac{\hat{a}x^{(0)}(1)}{\hat{b}x^{(0)}(1) + (\hat{a} - \hat{b}x^{(0)}(1))e^{\hat{a}k}},
$$
还原式为
$$
\hat{x}^{(0)}(k + 1) = \hat{x}^{(1)}(k + 1) - \hat{x}^{(1)}(k).
$$



## 马尔可夫预测
### 1.定义
设 $\{ \xi_n,\; n = 1, 2, ... \}$ 是一个随机序列，状态空间 $E$ 为有限集，对于任意正整数 $m, n$ ，
若 $i,j,i_k \in E(k = 1, ..., n - 1)$ ，有
$$
P\{\xi_{m + n} = j\; |\xi_n = i,\; \xi_{n - 1} = i_{n - 1}, ..., \xi_1 = i_1 \} = P\{\xi_{m + n} = j\; | \xi_n = i \},
$$
则称 $\{ \xi_n,\; n = 1, 2, ... \}$ 为一个马尔可夫链，上述等式称为马氏性。
对于上述等式，若 $m = 1$ 时成立，则其对于任意正整数 $m$ 也成立。

设 $\{ \xi_n,\; n = 1, 2, ... \}$ 为一个马氏链，若上述等式右边的条件概率与 $n$ 无关，即
$$
P\{ \xi_{m + n} = j\; |\xi_n = i \} = p_{ij}(m),
$$
则称 $\{ \xi_n,\; n = 1, 2, ... \}$ 为时齐的马尔可夫链，称 $p_{ij}(m)$ 为系统由状态 $i$ 经过 $m$ 个时间间隔转移到状态 $j$ 的转移概率。


### 2.转移概率矩阵及柯尔莫哥洛夫定理
对于一个马尔可夫链 $\{ \xi_n,\; n = 1, 2, ... \}$ ，称以 $m$ 步转移概率 $p_{ij}(m)$ 为元素的矩阵 $P(m) = (p_{ij}(m))$ 为马尔可夫链的 $m$ 步转移矩阵。当 $m = 1$ 时，记 $P(1) = P$ 称为马尔可夫链的一步转移矩阵。

马尔可夫转移矩阵的性质：
1）对 $\forall\; i, j \in E$ ，$0 \le p_{ij}(m) \le 1$ ；
2）对 $\forall\; i \in E$ ，$\sum\limits_{j \in E}p_{ij}(m) = 1$ ；
3）对 $\forall\; i, j \in E$ ，
$$
p_{ij}(0) = \delta_{ij} = 
\begin{cases}
1, & i = j, \\
0, & i \ne j.
\end{cases}
$$

柯尔莫哥洛夫-开普曼定理：
设 $\{ \xi_n,\; n = 1, 2, ... \}$ 为一个马尔可夫链，其状态空间 $E = \{ 1, 2, ... \}$ ，则对任意正整数 $m, n$ ，有
$$
p_{ij}(n + m) = \sum\limits_{k \in E}p_{ik}(n)p_{kj}(m),\quad i,j \in E
$$

设 $P$ 为一步马尔可夫链转移矩阵（ $P$ 的行向量是概率向量），$P^{(0)}$ 是初始分布行向量，则第 $n$ 步的概率分布为
$$
P^{(n)} = P^{(0)}P^n.
$$


### 3.极限概率分布
一个马尔可夫链的转移矩阵 $P$ 是正则的，当且仅当存在正整数 $k$ ，使 $P^k$ 的每一个元素都是正数。

若 $P$ 是一个马尔可夫链的正则矩阵，则
1）$P$ 有唯一的不动点向量 $W$ ，$W$ 的每个分量为正。
2）$P$ 的 $n$ 次幂 $P^n$ （$n$ 为正整数）随 $n$ 的增加趋于矩阵 $\overline{W}$ ， $\overline{W}$ 的每一行向量均等于不动点向量 $W$ ；


设时齐的马尔可夫链的状态空间为 $E$ ，若对于所有的 $i, j \in E$ ，转移概率 $p_{ij}(n)$ 存在极限
$$
\lim_{n \to \infty}p_{ij}(n) = \pi_j,
$$
则称此马尔可夫链具有遍历性。又若 $\sum\limits_j\pi_j = 1$ ，则同时称 $\pi = [\; \pi_1,\; \pi_2\; ... \;]$ 为此马尔可夫链的极限分布。


设时齐的马尔可夫链 $\{ \xi_n,\; n = 1, 2, ... \}$ 的状态空间 $E = \{ a_1, ..., a_N \}$ ，$P = (p_{ij})$ 是它的一步转移概率矩阵，若存在正整数 $m$ ，使得对 $\forall \; a_i, a_j \in E$ ，有
$$
p_{ij}(m) > 0,\quad i,j = 1, 2, ..., N,
$$
则称此马尔可夫链具有遍历性；且有极限分布 $\pi = [\; \pi_1,\; \pi_2,\; ...,\; \pi_N \;]$ ，它是方程组
$$
\pi = \pi P\; 或\; \pi_j = \sum\limits_{i = 1}^{N}\pi_i p_{ij},\quad j = 1, 2,..., N
$$
的满足条件
$$
\pi_j > 0,\quad \sum\limits_{j = 1}^N \pi_j = 1
$$
的唯一解。


